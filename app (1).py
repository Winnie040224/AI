# app.py
import os
import io
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import streamlit as st

from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             roc_auc_score, roc_curve, confusion_matrix, classification_report)
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline

# å¯é€‰ï¼šSHAPï¼ˆå¯è§£é‡Šæ€§ï¼‰
try:
    import shap
    _HAS_SHAP = True
except Exception:
    _HAS_SHAP = False

st.set_page_config(page_title="Telco Churn â€“ Streamlit Prototype", layout="wide")
st.title("ğŸ“± Telco Customer Churn â€“ Streamlit Prototype")

RANDOM_STATE = 42

# ============== Utilities ==============
@st.cache_data(show_spinner=False)
def load_data(default_path: str = "WA_Fn-UseC_-Telco-Customer-Churn.csv"):
    if os.path.exists(default_path):
        df = pd.read_csv(default_path)
        return df
    return None

def clean_transform_base(df_raw: pd.DataFrame) -> pd.DataFrame:
    df = df_raw.copy()
    # TotalCharges to numeric first
    if 'TotalCharges' in df.columns:
        df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
    # unify blanks to NaN
    df.replace([' ', 'NaN', 'N/A'], np.nan, inplace=True)
    # drop NaN
    df.dropna(inplace=True)

    # normalize "No internet/phone service"
    replace_cols = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport',
                    'StreamingTV','StreamingMovies','MultipleLines']
    for col in replace_cols:
        if col in df.columns:
            df[col] = df[col].replace({'No internet service':'No','No phone service':'No'})

    # 0/1 to Yes/No
    if 'SeniorCitizen' in df.columns:
        df['SeniorCitizen'] = df['SeniorCitizen'].replace({1:'Yes', 0:'No'})

    # drop obvious non-features if exist
    drop_cols = [c for c in ['customerID','gender','PhoneService'] if c in df.columns]
    if drop_cols:
        df.drop(drop_cols, axis=1, inplace=True)

    # keep only Yes/No target mapping
    if 'Churn' in df.columns:
        df = df[df['Churn'].isin(['Yes','No'])]

    return df

def split_xy(df: pd.DataFrame):
    y = df['Churn'].map({'Yes':1, 'No':0})
    X = df.drop('Churn', axis=1)
    cat_cols = X.select_dtypes(include=['object']).columns.tolist()
    num_cols = X.select_dtypes(exclude=['object']).columns.tolist()
    return X, y, cat_cols, num_cols

def make_preprocessor(cat_cols, num_cols):
    return ColumnTransformer(
        transformers=[
            ("cat", OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),
            ("num", "passthrough", num_cols)
        ]
    )

def plot_hist_kde(df, col):
    fig, ax = plt.subplots(figsize=(6,3.5))
    sns.histplot(df[col], kde=True, bins=30, ax=ax)
    ax.set_title(f"Distribution of {col}")
    st.pyplot(fig)

def plot_box(df, col):
    fig, ax = plt.subplots(figsize=(6,3.5))
    sns.boxplot(x=df[col], ax=ax)
    ax.set_title(f"Boxplot of {col}")
    st.pyplot(fig)

def plot_corr_heatmap(df_num, drop_col=None):
    corr = df_num.corr(numeric_only=True)
    if drop_col in corr.columns:
        corr = corr.drop(index=drop_col, columns=drop_col)
    fig, ax = plt.subplots(figsize=(8,6))
    sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", ax=ax)
    ax.set_title("Correlation Matrix")
    st.pyplot(fig)

def plot_count(series, title):
    fig, ax = plt.subplots(figsize=(4.5,3.5))
    series.value_counts().sort_index().plot(kind='bar', ax=ax)
    ax.set_title(title); ax.set_xlabel(series.name); ax.set_ylabel("Count")
    st.pyplot(fig)

def plot_confusion(cm, title):
    fig, ax = plt.subplots(figsize=(4.5,3.8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['No Churn','Churn'], yticklabels=['No Churn','Churn'], ax=ax)
    ax.set_title(title); ax.set_ylabel('Actual'); ax.set_xlabel('Predicted')
    st.pyplot(fig)

def metrics_table(y_true, y_pred, y_prob):
    acc = accuracy_score(y_true, y_pred)
    pre = precision_score(y_true, y_pred)
    rec = recall_score(y_true, y_pred)
    f1  = f1_score(y_true, y_pred)
    auc = roc_auc_score(y_true, y_prob) if y_prob is not None else np.nan
    return pd.DataFrame([{
        "Accuracy": acc, "Precision": pre, "Recall": rec, "F1-Score": f1, "ROC-AUC": auc
    }])

def plot_metrics_bars(report_dict, accuracy, title):
    df_report = pd.DataFrame(report_dict).transpose()
    metrics_df = df_report[['precision','recall','f1-score']].drop(
        ['accuracy','macro avg','weighted avg'], errors='ignore'
    )
    metrics_df = metrics_df.reset_index().rename(columns={'index':'Class'})
    melted = pd.melt(metrics_df, id_vars='Class', value_vars=['precision','recall','f1-score'],
                     var_name='Metric', value_name='Score')
    fig, ax = plt.subplots(figsize=(7.5,4.8))
    sns.barplot(data=melted, x='Class', y='Score', hue='Metric', ax=ax)
    ax.bar('Accuracy', accuracy, color='red', width=0.4, label='Accuracy')
    ax.set_title(f'{title} (Accuracy: {accuracy:.2f})'); ax.set_ylim(0,1); ax.grid(axis='y')
    handles, labels = ax.get_legend_handles_labels()
    if 'Accuracy' not in labels:
        handles.append(plt.Rectangle((0,0),1,1,color='red')); labels.append('Accuracy')
    ax.legend(handles=handles, labels=labels, title='Metric')
    st.pyplot(fig)

def plot_roc(y_true, y_prob, label):
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    auc_val = roc_auc_score(y_true, y_prob)
    plt.plot(fpr, tpr, label=f'{label} (AUC={auc_val:.3f})')


# ============== Data source ==============
st.sidebar.header("1) æ•°æ®æ¥æº / ä¸Šä¼ ")
df_default = load_data()
uploaded = st.sidebar.file_uploader("ä¸Šä¼  CSVï¼ˆå¯æ›¿ä»£å†…ç½®æ•°æ®ï¼‰", type=["csv"])

if uploaded is not None:
    df_raw = pd.read_csv(uploaded)
elif df_default is not None:
    df_raw = df_default
else:
    st.warning("æœªæ‰¾åˆ°é»˜è®¤æ•°æ®é›†ï¼Œè¯·å…ˆä¸Šä¼  CSVã€‚")
    st.stop()

st.success(f"å·²è½½å…¥æ•°æ®ï¼š{df_raw.shape[0]} è¡Œ Ã— {df_raw.shape[1]} åˆ—")

# ============== Cleaning preview ==============
with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®å‰å‡ è¡Œ", expanded=False):
    st.dataframe(df_raw.head())

df = clean_transform_base(df_raw)
st.info(f"æ¸…æ´—åæ•°æ®ï¼š{df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")

# Tabs
tab_eda, tab_pre, tab_train, tab_batch, tab_single, tab_shap = st.tabs([
    "ğŸ§­ EDA å¯è§†åŒ–", "ğŸ§ª é¢„å¤„ç†æ£€æŸ¥", "ğŸ‹ï¸ è®­ç»ƒä¸è¯„ä¼°", "ğŸ“¤ æ‰¹é‡é¢„æµ‹å¯¼å‡º", "ğŸ§ å•æ¡é¢„æµ‹", "ğŸ” å¯è§£é‡Šæ€§ï¼ˆSHAPï¼‰"
])

# ============== EDA Tab ==============
with tab_eda:
    st.subheader("æ¢ç´¢æ€§åˆ†æï¼ˆæ›¿ä»£ä½  Jupyter é‡Œçš„å›¾ï¼‰")

    # ç›´æ–¹å›¾/KDE + ç®±çº¿å›¾
    cols_num = df.select_dtypes(include=[np.number]).columns.tolist()
    # å°† TotalCharges è½¬æ•°å€¼åï¼Œå¯èƒ½åœ¨ df ä¸­è¿˜æ˜¯ object? æˆ‘ä»¬ä¸Šé¢å·²å¤„ç†
    left, right = st.columns(2)
    with left:
        col_for_hist = st.selectbox("é€‰æ‹©åˆ—ç»˜åˆ¶ç›´æ–¹å›¾/KDE", options=cols_num, index=cols_num.index('MonthlyCharges') if 'MonthlyCharges' in cols_num else 0)
        plot_hist_kde(df, col_for_hist)
    with right:
        col_for_box = st.selectbox("é€‰æ‹©åˆ—ç»˜åˆ¶ç®±çº¿å›¾", options=cols_num, index=cols_num.index('TotalCharges') if 'TotalCharges' in cols_num else 0)
        plot_box(df, col_for_box)

    # ç›¸å…³ç³»æ•°çƒ­åŠ›
    st.markdown("---")
    st.markdown("#### ç›¸å…³ç³»æ•°çƒ­åŠ›å›¾")
    df_num = df.select_dtypes(include=[np.number])
    drop_sc = 'SeniorCitizen' if 'SeniorCitizen' in df_num.columns else None
    plot_corr_heatmap(df_num, drop_col=drop_sc)

    # å¡æ–¹æ£€éªŒï¼ˆåˆ†ç±»åˆ—ï¼‰
    st.markdown("---")
    st.markdown("#### å¡æ–¹æ£€éªŒï¼ˆåˆ†ç±»åˆ— vs. Churnï¼‰")
    cat_cols_all = df.select_dtypes(include=['object']).columns.tolist()
    if 'customerID' in cat_cols_all:
        cat_cols_all.remove('customerID')
    if 'Churn' in cat_cols_all:
        cat_cols_all.remove('Churn')

    import scipy.stats as stats
    rows = []
    for col in cat_cols_all:
        contingency = pd.crosstab(df[col], df['Churn'])
        chi2, p, dof, exp = stats.chi2_contingency(contingency)
        rows.append([col, chi2, p, "âœ… Significant" if p < 0.05 else "âŒ Not significant"])
    chi_df = pd.DataFrame(rows, columns=["Feature","Chi2","p-value","Conclusion"])
    st.dataframe(chi_df)

# ============== Preprocessing Tab ==============
with tab_pre:
    st.subheader("é¢„å¤„ç†é…ç½®é¢„è§ˆ")
    X, y, cat_cols, num_cols = split_xy(df)
    st.write("**åˆ†ç±»ç‰¹å¾ï¼š**", cat_cols)
    st.write("**æ•°å€¼ç‰¹å¾ï¼š**", num_cols)
    st.write("**ç›®æ ‡åˆ†å¸ƒï¼ˆChurnï¼‰**")
    col1, col2 = st.columns(2)
    with col1:
        st.dataframe(y.value_counts().rename("count"))
    with col2:
        plot_count(y, "Churn åˆ†å¸ƒï¼ˆ0=No, 1=Yesï¼‰")

# ============== Train & Evaluate Tab ==============
with tab_train:
    st.subheader("è®­ç»ƒä¸è¯„ä¼°ï¼ˆKNN æ— /æœ‰ SMOTEã€Logisticã€RandomForestï¼‰")
    X, y, cat_cols, num_cols = split_xy(df)
    preprocessor = make_preprocessor(cat_cols, num_cols)

    test_size = st.slider("Test Size", 0.1, 0.4, 0.2, 0.05)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=RANDOM_STATE, stratify=y
    )

    # Pipelines
    pipe_knn = Pipeline(steps=[
        ("prep", preprocessor),
        ("scaler", StandardScaler(with_mean=False)),
        ("clf", KNeighborsClassifier(n_neighbors=5))
    ])

    pipe_knn_smote = ImbPipeline(steps=[
        ("prep", preprocessor),
        ("scaler", StandardScaler(with_mean=False)),
        ("smote", SMOTE(random_state=RANDOM_STATE)),
        ("clf", KNeighborsClassifier(n_neighbors=5))
    ])

    pipe_lr = Pipeline(steps=[
        ("prep", preprocessor),
        ("scaler", StandardScaler(with_mean=False)),
        ("clf", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))
    ])

    pipe_rf = Pipeline(steps=[
        ("prep", preprocessor),
        ("clf", RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE))
    ])

    colA, colB = st.columns(2)
    with colA:
        do_grid = st.checkbox("è½»é‡ç½‘æ ¼æœç´¢ï¼ˆKNN/LR/RFï¼‰", value=False)
    with colB:
        cv_folds = st.number_input("CV æŠ˜æ•°ï¼ˆGridSearchï¼‰", min_value=3, max_value=10, value=5, step=1)

    results = []
    roc_store = []

    def run_model(name, pipe, param_grid=None):
        if do_grid and param_grid:
            gs = GridSearchCV(pipe, param_grid=param_grid, cv=cv_folds, scoring='f1', n_jobs=-1)
            gs.fit(X_train, y_train)
            model = gs.best_estimator_
            best = gs.best_params_
        else:
            model = pipe.fit(X_train, y_train)
            best = None
        y_pred = model.predict(X_test)
        y_prob = model.predict_proba(X_test)[:,1] if hasattr(model, "predict_proba") else None
        mt = metrics_table(y_test, y_pred, y_prob)
        cm = confusion_matrix(y_test, y_pred)
        st.markdown(f"### {name}")
        if best: st.write("Best params:", best)
        st.dataframe(mt.style.format("{:.3f}"))

        plot_confusion(cm, f"{name} â€“ Confusion Matrix")

        rep = classification_report(y_test, y_pred, output_dict=True)
        plot_metrics_bars(rep, mt['Accuracy'].iloc[0], title=name)

        if y_prob is not None:
            roc_store.append((name, y_prob))
        results.append({"Model": name, **mt.iloc[0].to_dict(), "Estimator": model})

    # å‚æ•°ç½‘æ ¼ï¼ˆå¯é€‰ï¼‰
    param_knn = {"clf__n_neighbors": [5, 11]}
    param_lr  = {"clf__C": [0.1, 1.0, 10.0]}
    param_rf  = {"clf__max_depth": [None, 12], "clf__n_estimators":[200]}

    # Run all models
    run_model("KNN (No SMOTE)", pipe_knn, param_grid=param_knn)
    run_model("KNN (SMOTE)", pipe_knn_smote, param_grid=param_knn)
    run_model("Logistic Regression", pipe_lr, param_grid=param_lr)
    run_model("Random Forest", pipe_rf, param_grid=param_rf)

    # ROC curves
    if roc_store:
        fig = plt.figure(figsize=(6.5,5))
        for name, yprob in roc_store:
            plot_roc(y_test, yprob, name)
        plt.plot([0,1],[0,1],'k--', label='Random Guess')
        plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')
        plt.title('ROC Curves'); plt.legend(loc='lower right'); plt.grid(True)
        st.pyplot(fig)

    # Comparison table
    if results:
        df_cmp = pd.DataFrame([{k:v for k,v in d.items() if k != "Estimator"} for d in results])
        df_cmp = df_cmp.sort_values(by=["F1-Score","Recall","ROC-AUC"], ascending=False)
        st.markdown("### æ¨¡å‹å¯¹æ¯”è¡¨")
        st.dataframe(df_cmp.style.format({"Accuracy":"{:.3f}","Precision":"{:.3f}",
                                          "Recall":"{:.3f}","F1-Score":"{:.3f}","ROC-AUC":"{:.3f}"}))
        # ä¿å­˜åˆ° session_stateï¼Œä¾›å…¶å®ƒ tab ä½¿ç”¨
        st.session_state["models"] = results
        st.session_state["X_train"] = X_train
        st.session_state["y_train"] = y_train
        st.session_state["X_test"]  = X_test
        st.session_state["y_test"]  = y_test
        st.session_state["preprocessor"] = preprocessor
        st.session_state["cat_cols"] = cat_cols
        st.session_state["num_cols"] = num_cols

# ============== Batch scoring Tab ==============
with tab_batch:
    st.subheader("æ‰¹é‡é¢„æµ‹å¹¶å¯¼å‡º CSVï¼ˆæœ¬å‘¨ç›®æ ‡å®¢æˆ·æ¸…å•ï¼‰")
    if "models" not in st.session_state:
        st.warning("è¯·å…ˆåˆ°ã€è®­ç»ƒä¸è¯„ä¼°ã€æ ‡ç­¾é¡µè®­ç»ƒæ¨¡å‹ã€‚")
    else:
        # é€‰æ‹©ä¸€ä¸ªæ¨¡å‹
        model_names = [d["Model"] for d in st.session_state["models"]]
        chosen = st.selectbox("é€‰æ‹©ç”¨äºé¢„æµ‹çš„æ¨¡å‹", model_names, index=0)
        mdl = [d for d in st.session_state["models"] if d["Model"] == chosen][0]["Estimator"]

        st.markdown("ä¸Šä¼ å¾…é¢„æµ‹ CSVï¼ˆå­—æ®µå°½é‡ä¸è®­ç»ƒé›†ä¸€è‡´ï¼Œè‡³å°‘åŒ…å«ä½ ä¿ç•™çš„ç‰¹å¾åˆ—ï¼›æ— éœ€åŒ…å« Churnï¼‰")
        up = st.file_uploader("ä¸Šä¼ å¾…é¢„æµ‹æ•°æ®", type=["csv"], key="batch_upload")
        if up:
            df_new = pd.read_csv(up)
            df_new = clean_transform_base(df_new)
            if 'Churn' in df_new.columns:
                df_new = df_new.drop(columns=['Churn'])

            probs = mdl.predict_proba(df_new)[:,1] if hasattr(mdl, "predict_proba") else None
            preds = mdl.predict(df_new)
            out = df_new.copy()
            out['churn_probability'] = probs if probs is not None else preds
            out['churn_pred'] = preds

            st.dataframe(out.head())

            # ä¸‹è½½
            buf = io.StringIO()
            out.to_csv(buf, index=False)
            st.download_button("â¬‡ï¸ ä¸‹è½½ç›®æ ‡å®¢æˆ·æ¸…å• CSV", data=buf.getvalue(),
                               file_name="target_customers.csv", mime="text/csv")

# ============== Single prediction Tab ==============
with tab_single:
    st.subheader("å•æ¡å®¢æˆ·ä¿¡æ¯ â†’ å³æ—¶é¢„æµ‹")
    if "models" not in st.session_state:
        st.warning("è¯·å…ˆåˆ°ã€è®­ç»ƒä¸è¯„ä¼°ã€æ ‡ç­¾é¡µè®­ç»ƒæ¨¡å‹ã€‚")
    else:
        mdl = [d for d in st.session_state["models"] if d["Model"] == "Random Forest"][0]["Estimator"]
        # åŠ¨æ€ç”Ÿæˆè¾“å…¥æ§ä»¶
        schema = st.session_state["preprocessor"]
        X_cols = st.session_state["cat_cols"] + st.session_state["num_cols"]

        user_inputs = {}
        # ç®€åŒ–ï¼šä» df çš„åŒååˆ—ä¸­æŠ½å–ä¸€ä¸ªå‚è€ƒé€‰é¡¹
        sample_row = df.iloc[0]

        cols1, cols2 = st.columns(2)
        for i, col in enumerate(X_cols):
            if col in st.session_state["cat_cols"]:
                choices = sorted(df[col].dropna().unique().tolist())
                ui = (cols1 if i%2==0 else cols2).selectbox(f"{col}", choices, index=0)
            else:
                default_val = float(df[col].median()) if pd.api.types.is_numeric_dtype(df[col]) else 0.0
                ui = (cols1 if i%2==0 else cols2).number_input(f"{col}", value=float(default_val))
            user_inputs[col] = ui

        # é˜ˆå€¼ä¸æˆæœ¬
        st.markdown("---")
        thr = st.slider("åˆ¤å®šé˜ˆå€¼ï¼ˆè¶…è¿‡æ­¤æ¦‚ç‡å³åˆ¤ä¸º Churnï¼‰", 0.1, 0.9, 0.5, 0.01)
        benefit = st.number_input("æˆåŠŸæŒ½ç•™æ”¶ç›Šï¼ˆRMï¼‰", value=500.0, step=50.0)
        outreach_cost = st.number_input("è§¦è¾¾æˆæœ¬ï¼ˆRMï¼‰/äºº", value=50.0, step=10.0)

        if st.button("ğŸ”® é¢„æµ‹"):
            x_df = pd.DataFrame([user_inputs])
            prob = mdl.predict_proba(x_df)[:,1][0] if hasattr(mdl, "predict_proba") else float(mdl.predict(x_df)[0])
            pred = int(prob >= thr)
            st.metric("æµå¤±æ¦‚ç‡", f"{prob:.3f}")
            st.write("é¢„æµ‹æ ‡ç­¾ï¼š", "âš ï¸ Churn" if pred==1 else "âœ… No Churn")

            # ç®€å•â€œæœŸæœ›æ”¶ç›Šâ€
            expected_profit = (benefit - outreach_cost) if pred==1 else -outreach_cost
            st.write(f"**å»ºè®®**ï¼š{'çº³å…¥æŒ½ç•™åå•' if pred==1 else 'æš‚ä¸è§¦è¾¾'}ï¼›é¢„è®¡æœ¬å®¢æˆ·å‡€æ•ˆç›Šï¼šRM {expected_profit:.2f}")

# ============== SHAP Tab ==============
with tab_shap:
    st.subheader("SHAP å¯è§£é‡Šæ€§ï¼ˆä»¥ Random Forest ä¸ºä¾‹ï¼‰")
    if not _HAS_SHAP:
        st.info("æœªå®‰è£… shapï¼Œè¿è¡Œï¼špip install shap")
    elif "models" not in st.session_state:
        st.warning("è¯·å…ˆåˆ°ã€è®­ç»ƒä¸è¯„ä¼°ã€æ ‡ç­¾é¡µè®­ç»ƒæ¨¡å‹ã€‚")
    else:
        # å– RF æ¨¡å‹ä¸æµ‹è¯•é›†
        rf_list = [d for d in st.session_state["models"] if d["Model"] == "Random Forest"]
        if not rf_list:
            st.warning("è¯·å…ˆè®­ç»ƒ Random Forestã€‚")
        else:
            rf = rf_list[0]["Estimator"]
            X_test = st.session_state["X_test"]
            y_test = st.session_state["y_test"]

            st.caption("æ³¨ï¼šOneHot + æ ‘æ¨¡å‹ â†’ ä½¿ç”¨ TreeExplainer æ›´å¿«ï¼›ä¸‹æ–¹å±•ç¤ºå…¨å±€é‡è¦æ€§ + è‹¥å¹²å±€éƒ¨è§£é‡Šã€‚")
            try:
                # å–é¢„å¤„ç†åçš„ feature namesï¼ˆOneHot å±•å¼€ï¼‰
                prep = rf.named_steps["prep"]
                ohe = prep.named_transformers_["cat"]
                cat_out = ohe.get_feature_names_out(st.session_state["cat_cols"])
                feat_names = list(cat_out) + st.session_state["num_cols"]

                # å˜æ¢æµ‹è¯•é›†åˆ°æ¨¡å‹è¾“å…¥ç©ºé—´
                X_test_trans = prep.transform(X_test)
                # å¦‚æœæ˜¯ RFï¼ŒTreeExplainer é€‚é…
                explainer = shap.TreeExplainer(rf.named_steps["clf"])
                shap_values = explainer.shap_values(X_test_trans)

                st.markdown("**å…¨å±€ç‰¹å¾é‡è¦æ€§ï¼ˆmean |SHAP|ï¼‰**")
                fig = plt.figure(figsize=(7.5,5))
                shap.summary_plot(shap_values[1], X_test_trans, feature_names=feat_names, show=False)
                st.pyplot(fig, clear_figure=True)

                # å±€éƒ¨è§£é‡Šï¼ˆå±•ç¤ºå‰ 3 æ¡ï¼‰
                st.markdown("---")
                st.markdown("**å±€éƒ¨è§£é‡Šï¼ˆå‰ 3 ä¸ªæ ·æœ¬ï¼‰**")
                for i in range(min(3, X_test_trans.shape[0])):
                    st.write(f"æ ·æœ¬ #{i}")
                    fig2 = plt.figure(figsize=(7,3.8))
                    shap.force_plot(explainer.expected_value[1], shap_values[1][i,:], 
                                    matplotlib=True, show=False)
                    st.pyplot(fig2, clear_figure=True)

            except Exception as e:
                st.error(f"SHAP å¯è§†åŒ–å¤±è´¥ï¼š{e}")
                st.info("æç¤ºï¼šä¸åŒ shap ç‰ˆæœ¬ä¸ç¨€ç–/ç¨ å¯†çŸ©é˜µå…¼å®¹æ€§å¯èƒ½å¯¼è‡´é”™è¯¯ï¼›å¿…è¦æ—¶å…ˆå°†è¾“å…¥è½¬ä¸º denseã€‚")
